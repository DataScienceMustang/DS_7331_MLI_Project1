{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is the Jupyter notebook for the Machine Learning 1 Lab 1\n",
    "# Author: Tom Pengilly\n",
    "# Group Members: Tom Pengilly, Quynh Chao, Michael Weatherford, Anish Patel\n",
    "# Date: 9/3/2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Business Understanding (This Section has no code)\n",
    "\n",
    "# What is the purpose of the data? (WHy was it collected?)\n",
    "# How would you define and measure the outcomes from the dataset.... \n",
    "# ....(Why is the data important and how do you know if you have mined useful knowledge from the dataset?)\n",
    "# How would you measure the effectiveness of a good prediction algorithm? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Understanding: The following section includes the code used to aggregate the 5 data files into 1 combined dataset, data wrangling, missing/outlier handling, imputation, visualization, attribute relations, and interesting findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling: The data wrangling code used to concatenate, clean, and convert our data is shown below.  The first section deals with creating our final dataset for use in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Data Understanding ########## \n",
    "\n",
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import set_option\n",
    "set_option('display.max_columns',400)\n",
    "from pandas_profiling import ProfileReport\n",
    "import copy as cp\n",
    "import os\n",
    "import glob\n",
    "import matplotlib as plt\n",
    "import re\n",
    "import datetime\n",
    "from scipy.stats import ks_2samp, ttest_ind\n",
    "# from pandas.tools.plotting import scatter_matrix # #??? Need this?\n",
    "# from pandas.tools.plotting import parallel_coordinates\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all data files and create the combined dataset\n",
    "os.chdir('C:\\\\Users\\\\Tpeng\\\\OneDrive\\\\Documents\\\\SMU\\\\Term 3\\\\Machine Learning\\\\Lab1\\\\DatasetAndPreprocessing')\n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "#Read and Concat all data files (excluding the combined dataset created later stored here)\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "i = 0\n",
    "\n",
    "for obs in all_files:\n",
    "    if re.search('Combined_Dataset', obs):\n",
    "        print(i)\n",
    "        i += 1\n",
    "        all_files.remove(obs)\n",
    "    else:\n",
    "        i += 1\n",
    "        \n",
    "property_data = []\n",
    "\n",
    "# Create the combined dataset\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    property_data.append(df)\n",
    "\n",
    "combineddf = pd.concat(property_data, axis=0, ignore_index=True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat attributes in order to explore/change them more easily\n",
    "# Split variables into ordinal, continuous and categorical\n",
    "ordinal_vars = ['rooms', 'bedrooms', 'bathrooms' ]\n",
    "continuous_vars = ['lat', 'lon', 'surface_total', 'surface_covered', 'price']\n",
    "categorical_vars = ['ad_type', 'l1', 'l2', 'l3', 'l4', 'l5', 'l6', 'currency', 'price_period', 'property_type', 'operation_type']\n",
    "string_vars = ['id', 'title', 'description']\n",
    "time_vars = ['start_date', 'end_date', 'created_on']\n",
    "\n",
    "# Create a dataframe with  missing values as -1 or 0 (this is done to allow the datatypes to be changed)\n",
    "# dates of 9999-12-31 have not yet expired, but are replaced w/ 1970-01-01 since this value is used to determine exchange rates\n",
    "combineddf[ordinal_vars] = combineddf[ordinal_vars].replace(to_replace = np.nan, value = -1)\n",
    "combineddf[time_vars] = combineddf[time_vars].replace(to_replace = \"9999-12-31\", value = 0)\n",
    "\n",
    "# Change data types\n",
    "combineddf[ordinal_vars] = combineddf[ordinal_vars].astype(np.int64)\n",
    "combineddf[continuous_vars] = combineddf[continuous_vars].astype(np.float64)\n",
    "combineddf[categorical_vars] = combineddf[categorical_vars].astype('category')\n",
    "combineddf[string_vars] = combineddf[string_vars].astype(str)\n",
    "combineddf[time_vars] = pd.to_datetime(combineddf[time_vars].stack(), format = \"%Y-%m-%d\").unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove listings that have not yet expired (end date 9999-12-31)\n",
    "indices = []\n",
    "for row in range(len(combineddf)):\n",
    "    if combineddf.end_date[row].strftime('%Y-%m-%d') == '1970-01-01':\n",
    "        indices.append(row)\n",
    "reduceddf = combineddf.drop(combineddf.index[indices], inplace = False)\n",
    "reduceddf = reduceddf.reset_index(drop=True)\n",
    "\n",
    "# Remove listings that have no price or currency\n",
    "indices = []\n",
    "for row in range(len(reduceddf)):\n",
    "    if reduceddf.price[row] == 0:\n",
    "        indices.append(row)\n",
    "    if pd.isnull(reduceddf.price[row]):\n",
    "        indices.append(row)\n",
    "    if pd.isnull(reduceddf.currency[row]):\n",
    "        indices.append(row)\n",
    "reduceddf2 = reduceddf.drop(combineddf.index[indices], inplace = False)\n",
    "reduceddf2 = reduceddf2.reset_index(drop=True)\n",
    "\n",
    "# Combine factor levels that are equivalent\n",
    "reduceddf2 = reduceddf2.replace(to_replace = 'Estados Unidos de América', value = 'Estado Unidos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used to read in historical exchange rate data between all currencies and USD. This data is used to convert all prices to the same scale. The transaction end_date was used as the date of exchange, if the date isn't listed in the price histories, the date is decremented until a recent exchange rate was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduceddf2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5dd59c43b314>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Convert price in reduceddf to USD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduceddf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreduceddf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'USD'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mcurrency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduceddf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reduceddf2' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert prices to USD using exchange rate histories.  All price histories from https://www.investing.com/currencies/\n",
    "# The exchange rate for the given currency pair is looked up for the end_date\n",
    "arsusd = pd.read_csv('C:\\\\Users\\\\Tpeng\\OneDrive\\\\Documents\\\\SMU\\\\Term 3\\\\Machine Learning\\\\Lab1\\\\Price Data\\\\USD_ARS Historical Data.csv', header = 0)\n",
    "copusd = pd.read_csv('C:\\\\Users\\\\Tpeng\\OneDrive\\\\Documents\\\\SMU\\\\Term 3\\\\Machine Learning\\\\Lab1\\\\Price Data\\\\USD_COP Historical Data.csv', header = 0)\n",
    "penusd = pd.read_csv('C:\\\\Users\\\\Tpeng\\OneDrive\\\\Documents\\\\SMU\\\\Term 3\\\\Machine Learning\\\\Lab1\\\\Price Data\\\\USD_PEN Historical Data.csv', header = 0)\n",
    "uyuusd = pd.read_csv('C:\\\\Users\\\\Tpeng\\OneDrive\\\\Documents\\\\SMU\\\\Term 3\\\\Machine Learning\\\\Lab1\\\\Price Data\\\\USD_UYU Historical Data.csv', header = 0)\n",
    "\n",
    "\n",
    "# Convert price in reduceddf to USD \n",
    "for obs in range(len(reduceddf2)):\n",
    "    if reduceddf2.currency[obs] != 'USD':\n",
    "        currency = reduceddf2.currency[obs]\n",
    "        date = reduceddf2.end_date[obs]\n",
    "        \n",
    "        if date.strftime('%Y-%m-%d') != '1970-01-01':\n",
    "            if reduceddf2.currency[obs] == 'ARS':\n",
    "                while date.strftime('%Y-%m-%d') not in list(arsusd.Date):\n",
    "                    date = date - datetime.timedelta(days = 1)\n",
    "                exchange_rate = arsusd.Price[arsusd.Date == date.strftime('%Y-%m-%d')]\n",
    "                reduceddf2.at[obs, 'price'] = reduceddf2.price[obs] / float(exchange_rate)\n",
    "                reduceddf2.at[obs, 'currency'] = 'USD'\n",
    "            if reduceddf2.currency[obs] == 'UYU':\n",
    "                while date.strftime('%Y-%m-%d') not in list(uyuusd.Date):\n",
    "                    date -= datetime.timedelta(days = 1)\n",
    "                exchange_rate = uyuusd.Price[uyuusd.Date == date.strftime('%Y-%m-%d')]\n",
    "                reduceddf2.at[obs, 'price'] = reduceddf2.price[obs] / float(exchange_rate)\n",
    "                reduceddf2.at[obs, 'currency'] = 'USD'\n",
    "            if reduceddf2.currency[obs] == 'PEN':\n",
    "                while date.strftime('%Y-%m-%d') not in list(penusd.Date):\n",
    "                    date -= datetime.timedelta(days = 1)\n",
    "                exchange_rate = penusd.Price[penusd.Date == date.strftime('%Y-%m-%d')]\n",
    "                reduceddf2.at[obs, 'price'] = reduceddf2.price[obs] / float(exchange_rate)\n",
    "                reduceddf2.at[obs, 'currency'] = 'USD'\n",
    "            if reduceddf2.currency[obs] == 'COP':\n",
    "                while date.strftime('%Y-%m-%d') not in list(copusd.Date):\n",
    "                    date -= datetime.timedelta(days = 1)\n",
    "                exchange_rate = copusd.Price[copusd.Date == date.strftime('%Y-%m-%d')]\n",
    "                reduceddf2.at[obs, 'price'] = reduceddf2.price[obs] / float(exchange_rate)\n",
    "                reduceddf2.at[obs, 'currency'] = 'USD'\n",
    "                \n",
    "# The dataset is saved as a new file at this point\n",
    "#reduceddf2.to_csv(\"Converted_Dataset.csv\", sep = ',')\n",
    "#converted_data = pd.read_csv('C:\\\\Users\\\\Tpeng\\\\OneDrive\\\\Documents\\\\SMU\\\\Term 3\\\\Machine Learning\\\\Lab1\\\\Datasets\\\\Converted_Dataset.csv', sep = ',', header = 0)\n",
    "converted_data = reduceddf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe filled with only missing values to determine appropriate action\n",
    "missing_dates = converted_data[converted_data.start_date.isna() & converted_data.end_date.isna() & converted_data.created_on.isna()]\n",
    "\n",
    "# These 65 observations are missing all dates, countries, prices, currency, etc... remove these\n",
    "converted_data2 = converted_data[~converted_data['Unnamed: 0'].isin(missing_dates['Unnamed: 0'])]\n",
    "\n",
    "# Reset indices on converted_data2\n",
    "converted_data2 = converted_data2.reset_index(drop=True)\n",
    "\n",
    "# Rename index column\n",
    "converted_data2 = converted_data2.rename(columns={'Unnamed: 0': 'Index'})\n",
    "\n",
    "# Replace innapropriate -1 values with np.nan and remove duplicates\n",
    "converted_data2 = converted_data2.replace(to_replace = (-1, -2, -3), value = np.nan)\n",
    "converted_data2.drop_duplicates(keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace negative surface_total and surface_covered values with nan\n",
    "converted_data2.surface_covered.replace(to_replace = -152, value = np.nan, inplace = True)\n",
    "converted_data2.surface_covered.replace(to_replace = -4, value = np.nan, inplace = True)\n",
    "converted_data2.surface_total.replace(to_replace = -36, value = np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tpeng\\Anaconda3\\envs\\renv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "###### FOR CONVENIENCE ####### Load the converted_data \n",
    "os.chdir('C:\\\\Users\\\\Tpeng\\\\OneDrive\\\\Documents\\\\SMU\\\\Term 3\\\\Machine Learning\\\\Lab1\\\\')\n",
    "path = os.getcwd()\n",
    "converted_data2 = pd.read_csv('C:\\\\Users\\\\Tpeng\\\\OneDrive\\\\Documents\\\\SMU\\\\Term 3\\\\Machine Learning\\\\Lab1\\\\Datasets\\\\Converted_Dataset2.csv', sep = ',', header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>id</th>\n",
       "      <th>ad_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>created_on</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>l4</th>\n",
       "      <th>l5</th>\n",
       "      <th>l6</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>surface_total</th>\n",
       "      <th>surface_covered</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>price_period</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>property_type</th>\n",
       "      <th>operation_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jgIzAKLaljBee5xKVoCs3A==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>-34.643029</td>\n",
       "      <td>-58.368769</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>Barracas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>556.438792</td>\n",
       "      <td>USD</td>\n",
       "      <td>Mensual</td>\n",
       "      <td>PH 5 AMB CON AMPLIA TERRAZA Y BALCÓN</td>\n",
       "      <td>CODIGO: 4429-11 ubicado en: AVENIDA PATRICIOS ...</td>\n",
       "      <td>PH</td>\n",
       "      <td>Alquiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>kzR5ghTwqnCfkf1A1CU6HA==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>-34.476510</td>\n",
       "      <td>-58.534146</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bs.As. G.B.A. Zona Norte</td>\n",
       "      <td>San Isidro</td>\n",
       "      <td>San Isidro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.150521</td>\n",
       "      <td>USD</td>\n",
       "      <td>Mensual</td>\n",
       "      <td>PH - Las Lomas-San Isidro</td>\n",
       "      <td>ALQUILER PH SIN EXPENSAS SAN ISIDRO  Don Bosco...</td>\n",
       "      <td>PH</td>\n",
       "      <td>Alquiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M60/Oh5ToxGELDNQHKASrQ==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bs.As. G.B.A. Zona Norte</td>\n",
       "      <td>Tigre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>757.575758</td>\n",
       "      <td>USD</td>\n",
       "      <td>Mensual</td>\n",
       "      <td>Venta. Alquiler anual.  Casa estilo moderno. 5...</td>\n",
       "      <td>MAM (2). Hermosa casa diseñada en una planta, ...</td>\n",
       "      <td>Casa</td>\n",
       "      <td>Alquiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pjPcCHWnjKcN05hNhI0ssg==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bs.As. G.B.A. Zona Norte</td>\n",
       "      <td>Tigre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>757.575758</td>\n",
       "      <td>USD</td>\n",
       "      <td>Mensual</td>\n",
       "      <td>ALQUILER  Casa estilo racionalista en una plan...</td>\n",
       "      <td>MAM. Hermosa casa diseñada en una planta, con ...</td>\n",
       "      <td>Casa</td>\n",
       "      <td>Alquiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0Py/8IGj4qZsfLk7lEgPvA==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>-31.431401</td>\n",
       "      <td>-64.225170</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Córdoba</td>\n",
       "      <td>Córdoba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>123.915737</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consultorio en alquiler</td>\n",
       "      <td>Consultorio ideal para centro de estética, pos...</td>\n",
       "      <td>Oficina</td>\n",
       "      <td>Alquiler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                        id    ad_type  start_date    end_date  \\\n",
       "0      0  jgIzAKLaljBee5xKVoCs3A==  Propiedad  2019-09-15  2020-03-15   \n",
       "1      1  kzR5ghTwqnCfkf1A1CU6HA==  Propiedad  2019-09-15  2019-09-21   \n",
       "2      2  M60/Oh5ToxGELDNQHKASrQ==  Propiedad  2019-09-15  2019-10-29   \n",
       "3      3  pjPcCHWnjKcN05hNhI0ssg==  Propiedad  2019-09-15  2019-10-29   \n",
       "4      4  0Py/8IGj4qZsfLk7lEgPvA==  Propiedad  2019-09-15  2019-09-17   \n",
       "\n",
       "   created_on        lat        lon         l1                        l2  \\\n",
       "0  2019-09-15 -34.643029 -58.368769  Argentina           Capital Federal   \n",
       "1  2019-09-15 -34.476510 -58.534146  Argentina  Bs.As. G.B.A. Zona Norte   \n",
       "2  2019-09-15        NaN        NaN  Argentina  Bs.As. G.B.A. Zona Norte   \n",
       "3  2019-09-15        NaN        NaN  Argentina  Bs.As. G.B.A. Zona Norte   \n",
       "4  2019-09-15 -31.431401 -64.225170  Argentina                   Córdoba   \n",
       "\n",
       "           l3          l4   l5   l6  rooms  bedrooms  bathrooms  \\\n",
       "0    Barracas         NaN  NaN  NaN    NaN       NaN        NaN   \n",
       "1  San Isidro  San Isidro  NaN  NaN    4.0       NaN        2.0   \n",
       "2       Tigre         NaN  NaN  NaN    5.0       NaN        2.0   \n",
       "3       Tigre         NaN  NaN  NaN    5.0       NaN        2.0   \n",
       "4     Córdoba         NaN  NaN  NaN    2.0       NaN        1.0   \n",
       "\n",
       "   surface_total  surface_covered       price currency price_period  \\\n",
       "0            NaN              NaN  556.438792      USD      Mensual   \n",
       "1          110.0              NaN  441.150521      USD      Mensual   \n",
       "2          190.0            160.0  757.575758      USD      Mensual   \n",
       "3          190.0            160.0  757.575758      USD      Mensual   \n",
       "4           40.0             40.0  123.915737      USD          NaN   \n",
       "\n",
       "                                               title  \\\n",
       "0               PH 5 AMB CON AMPLIA TERRAZA Y BALCÓN   \n",
       "1                          PH - Las Lomas-San Isidro   \n",
       "2  Venta. Alquiler anual.  Casa estilo moderno. 5...   \n",
       "3  ALQUILER  Casa estilo racionalista en una plan...   \n",
       "4                            Consultorio en alquiler   \n",
       "\n",
       "                                         description property_type  \\\n",
       "0  CODIGO: 4429-11 ubicado en: AVENIDA PATRICIOS ...            PH   \n",
       "1  ALQUILER PH SIN EXPENSAS SAN ISIDRO  Don Bosco...            PH   \n",
       "2  MAM (2). Hermosa casa diseñada en una planta, ...          Casa   \n",
       "3  MAM. Hermosa casa diseñada en una planta, con ...          Casa   \n",
       "4  Consultorio ideal para centro de estética, pos...       Oficina   \n",
       "\n",
       "  operation_type  \n",
       "0       Alquiler  \n",
       "1       Alquiler  \n",
       "2       Alquiler  \n",
       "3       Alquiler  \n",
       "4       Alquiler  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the extra index column and display header\n",
    "converted_data2 = converted_data2.drop(['Unnamed: 0'], axis = 1)\n",
    "converted_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tpeng\\Anaconda3\\envs\\renv\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Remove empty property_type listings\n",
    "prop_cats = ['Departamento',\n",
    " 'Otro',\n",
    " 'Casa',\n",
    " 'Apartamento',\n",
    " 'Lote',\n",
    " 'Local comercial',\n",
    " 'Oficina',\n",
    " 'PH',\n",
    " 'Depósito',\n",
    " 'Finca',\n",
    " 'Cochera',\n",
    " 'Parqueadero',\n",
    " 'Casa de campo',\n",
    " 'Garaje']\n",
    "\n",
    "final_df = converted_data2[converted_data2['property_type'].isin(prop_cats)]\n",
    "props = final_df.property_type.astype('category')\n",
    "final_df.drop(labels = 'property_type', axis = 'columns', inplace = True)\n",
    "\n",
    "final_df['property_type'] = props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dataset is the *Final* dataset to be used for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all non- South American Countries\n",
    "countries = ['Argentina', 'Brasil', 'Columbia', 'Ecuador', 'Perú', 'Uruguay']\n",
    "final_df = final_df[final_df['l1'].isin(countries)]\n",
    "final_df.l1 = final_df['l1'].astype('category')\n",
    "final_df = final_df[final_df.operation_type == 'Venta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset into R dataframe\n",
    "Rdf = robjects.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Verify data quality.\n",
    "# Explain and address missing values, duplicate data, and outliers. Are they mistakes? How do you deal with them? Be specific.\n",
    "# Insert Preprocessing code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Give appropriate statistics of the most important attributes in data\n",
    "# Range, mode, mean, median, variance, counts, etc...\n",
    "# Describe what they mean or if you found something interesting about them\n",
    "# You can use data from other sources for comparison\n",
    "# Explain significance of the statistics run and why they are meaningful\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualize the most important attributes appropriately (AT LEAST 5 ATTRIBUTES)\n",
    "# Provide an interpretation for each chart\n",
    "# Explain each attribute why the chosen visualization is appropriate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Explain relationships b/t attributes\n",
    "# Scatterplots, correlations, cross-tabulation, group-wise averages, etc. as appropriate and explain interesting relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Identify and explain interesting relationships b/t features and the class you are trying to predict (ie. rel b/t\n",
    "# vars and the target classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Are there other features that could be added to the data or created from existing features? Which ones?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Exceptional Work ##########\n",
    "\n",
    "# Free reign to provide additional analyses\n",
    "# Idea: implement dimensionality reduction, then visualize and interpret the results\n",
    "\n",
    "# Other Ideas:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
